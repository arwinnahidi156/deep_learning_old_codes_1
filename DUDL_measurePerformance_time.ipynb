{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# New!\n",
    "import time\n",
    "# Well, OK, it's not really new. See, e.g., DUDL_metaparams_CodeChallengeBatches\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "\n",
    "data = pd.read_csv('./mnist_train.csv')\n",
    "data=np.array(data)\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize  = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # Start the timer!\n",
    "  timerInFunction = time.process_time()\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "    # Finally, report the epoch number, computation time, and accuracy\n",
    "    comptime = time.process_time() - timerInFunction\n",
    "    print(f'Epoch {epochi+1}/{numepochs}, elapsed time: {comptime:.2f} sec, test accuracy {testAcc[-1]:.0f}%')\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, elapsed time: 16.61 sec, test accuracy 93%\n",
      "Epoch 2/10, elapsed time: 32.77 sec, test accuracy 94%\n",
      "Epoch 3/10, elapsed time: 48.39 sec, test accuracy 95%\n",
      "Epoch 4/10, elapsed time: 63.82 sec, test accuracy 95%\n",
      "Epoch 5/10, elapsed time: 78.29 sec, test accuracy 96%\n",
      "Epoch 6/10, elapsed time: 92.35 sec, test accuracy 96%\n",
      "Epoch 7/10, elapsed time: 106.64 sec, test accuracy 96%\n",
      "Epoch 8/10, elapsed time: 120.32 sec, test accuracy 96%\n",
      "Epoch 9/10, elapsed time: 134.26 sec, test accuracy 96%\n",
      "Epoch 10/10, elapsed time: 148.92 sec, test accuracy 96%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainAcc,testAcc,losses,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, elapsed time: 13.53 sec, test accuracy 91%\n",
      "Epoch 2/10, elapsed time: 28.58 sec, test accuracy 94%\n",
      "Epoch 3/10, elapsed time: 43.23 sec, test accuracy 94%\n",
      "Epoch 4/10, elapsed time: 57.07 sec, test accuracy 96%\n",
      "Epoch 5/10, elapsed time: 71.24 sec, test accuracy 95%\n",
      "Epoch 6/10, elapsed time: 85.84 sec, test accuracy 96%\n",
      "Epoch 7/10, elapsed time: 100.23 sec, test accuracy 95%\n",
      "Epoch 8/10, elapsed time: 114.23 sec, test accuracy 96%\n",
      "Epoch 9/10, elapsed time: 128.66 sec, test accuracy 96%\n",
      "Epoch 10/10, elapsed time: 143.65 sec, test accuracy 96%\n",
      "Epoch 1/10, elapsed time: 14.46 sec, test accuracy 93%\n",
      "Epoch 2/10, elapsed time: 30.12 sec, test accuracy 93%\n",
      "Epoch 3/10, elapsed time: 45.54 sec, test accuracy 95%\n",
      "Epoch 4/10, elapsed time: 60.24 sec, test accuracy 95%\n",
      "Epoch 5/10, elapsed time: 77.25 sec, test accuracy 95%\n",
      "Epoch 6/10, elapsed time: 92.13 sec, test accuracy 96%\n",
      "Epoch 7/10, elapsed time: 106.02 sec, test accuracy 96%\n",
      "Epoch 8/10, elapsed time: 119.21 sec, test accuracy 96%\n",
      "Epoch 9/10, elapsed time: 132.02 sec, test accuracy 96%\n",
      "Epoch 10/10, elapsed time: 144.85 sec, test accuracy 96%\n",
      "Epoch 1/10, elapsed time: 13.14 sec, test accuracy 94%\n",
      "Epoch 2/10, elapsed time: 25.86 sec, test accuracy 94%\n",
      "Epoch 3/10, elapsed time: 38.68 sec, test accuracy 94%\n",
      "Epoch 4/10, elapsed time: 52.57 sec, test accuracy 95%\n",
      "Epoch 5/10, elapsed time: 67.59 sec, test accuracy 95%\n",
      "Epoch 6/10, elapsed time: 82.53 sec, test accuracy 96%\n",
      "Epoch 7/10, elapsed time: 98.30 sec, test accuracy 96%\n",
      "Epoch 8/10, elapsed time: 113.74 sec, test accuracy 96%\n",
      "Epoch 9/10, elapsed time: 128.91 sec, test accuracy 95%\n",
      "Epoch 10/10, elapsed time: 143.88 sec, test accuracy 96%\n",
      "Epoch 1/10, elapsed time: 14.75 sec, test accuracy 93%\n",
      "Epoch 2/10, elapsed time: 29.85 sec, test accuracy 95%\n",
      "Epoch 3/10, elapsed time: 44.92 sec, test accuracy 95%\n",
      "Epoch 4/10, elapsed time: 59.84 sec, test accuracy 95%\n",
      "Epoch 5/10, elapsed time: 74.92 sec, test accuracy 96%\n",
      "Epoch 6/10, elapsed time: 91.07 sec, test accuracy 96%\n",
      "Epoch 7/10, elapsed time: 106.77 sec, test accuracy 96%\n",
      "Epoch 8/10, elapsed time: 122.14 sec, test accuracy 95%\n",
      "Epoch 9/10, elapsed time: 138.11 sec, test accuracy 95%\n",
      "Epoch 10/10, elapsed time: 154.17 sec, test accuracy 96%\n",
      "Epoch 1/10, elapsed time: 14.93 sec, test accuracy 94%\n",
      "Epoch 2/10, elapsed time: 30.10 sec, test accuracy 94%\n",
      "Epoch 3/10, elapsed time: 45.05 sec, test accuracy 95%\n",
      "Epoch 4/10, elapsed time: 60.09 sec, test accuracy 94%\n",
      "Epoch 5/10, elapsed time: 75.02 sec, test accuracy 96%\n",
      "Epoch 6/10, elapsed time: 90.35 sec, test accuracy 95%\n",
      "Epoch 7/10, elapsed time: 106.14 sec, test accuracy 96%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m timerOutsideFunction \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   function2trainTheModel()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m TotalExperimentTime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m timerOutsideFunction\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mTotal elapsed experiment time: \u001b[39m\u001b[39m{\u001b[39;00mTotalExperimentTime\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m minutes\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m loss \u001b[39m=\u001b[39m lossfun(yHat,y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# backprop\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arwin/jupyter/DUDL_measurePerformance_time.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/jupyter/environment/lib/python3.10/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_dynamo\u001b[39m.\u001b[39;49mdisable(fn, recursive)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jupyter/environment/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:328\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    327\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    329\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/jupyter/environment/lib/python3.10/site-packages/torch/optim/optimizer.py:803\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    801\u001b[0m     per_device_and_dtype_grads \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 803\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_profile_name):\n\u001b[1;32m    804\u001b[0m     \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    805\u001b[0m         \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m group[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/jupyter/environment/lib/python3.10/site-packages/torch/autograd/profiler.py:631\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\n\u001b[1;32m    633\u001b[0m     )\n\u001b[1;32m    634\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/jupyter/environment/lib/python3.10/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# now run a second timer over repeated iterations\n",
    "\n",
    "# Start the timer! (note the different variable name)\n",
    "timerOutsideFunction = time.process_time()\n",
    "\n",
    "for i in range(10):\n",
    "  function2trainTheModel()\n",
    "\n",
    "TotalExperimentTime = time.process_time() - timerOutsideFunction\n",
    "print(f'\\n\\n\\nTotal elapsed experiment time: {TotalExperimentTime/60:.2f} minutes')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
